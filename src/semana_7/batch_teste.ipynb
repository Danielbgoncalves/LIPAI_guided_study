{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6851d861",
   "metadata": {},
   "source": [
    "# Influência do tamanho do batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69875560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6220b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785946e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['pclass', 'female', 'age', 'fare'] # classe, feminino, idade, preço da passagem\n",
    "titanic_df['female'] = titanic_df['sex'].map({'male': 0, 'female':1})\n",
    "titanic_df['alive'] = titanic_df['alive'].map({'no': 0, 'yes':1})\n",
    "titanic_df.dropna(subset=feature_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4da07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_df[feature_names].to_numpy()\n",
    "Y = titanic_df['alive'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3a0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fafb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89dc70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassBin(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(ClassBin, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 4)    # primeira hidden layer\n",
    "        self.dropout1 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear2 = nn.Linear(4, 4)    # segunda hidden layer\n",
    "        self.dropout2 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear3 = nn.Linear(4, 1)    # terceira hidden layer\n",
    "        self.dropout3 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ClassBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassBin(nn.Module):\n",
    "#     # Construtor\n",
    "#     def __init__(self):\n",
    "#         super(ClassBin, self).__init__()\n",
    "#         self.fc1 = nn.Linear(4, 20) # primeira hidden layer\n",
    "#         self.fc2 = nn.Linear(20, 1) # segunda hidden layer\n",
    "#         self.sigmoid = nn.Sigmoid() # output layer com ativação Sigmoid\n",
    "\n",
    "#     # Propagação (Feed Forward)\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# model = ClassBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36a8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "epochs = 100\n",
    "batch_size = 4  # X_train 535 / 32 = 16.71 (então são 17 batches de 32)\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Instânciar o Otimizador Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d59c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Converter X e y para torch.Tensor\n",
    "X_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(x_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# Um Dataset de Tensores - Array [X, y]\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793aa19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1,\n",
      "          Custo Treino: 0.693\n",
      "Época 2,\n",
      "          Custo Treino: 0.693\n",
      "Época 3,\n",
      "          Custo Treino: 0.693\n",
      "Época 4,\n",
      "          Custo Treino: 0.693\n",
      "Época 5,\n",
      "          Custo Treino: 0.693\n",
      "Época 6,\n",
      "          Custo Treino: 0.693\n",
      "Época 7,\n",
      "          Custo Treino: 0.693\n",
      "Época 8,\n",
      "          Custo Treino: 0.693\n",
      "Época 9,\n",
      "          Custo Treino: 0.693\n",
      "Época 10,\n",
      "          Custo Treino: 0.693\n",
      "Época 11,\n",
      "          Custo Treino: 0.693\n",
      "Época 12,\n",
      "          Custo Treino: 0.693\n",
      "Época 13,\n",
      "          Custo Treino: 0.693\n",
      "Época 14,\n",
      "          Custo Treino: 0.693\n",
      "Época 15,\n",
      "          Custo Treino: 0.693\n",
      "Época 16,\n",
      "          Custo Treino: 0.693\n",
      "Época 17,\n",
      "          Custo Treino: 0.693\n",
      "Época 18,\n",
      "          Custo Treino: 0.693\n",
      "Época 19,\n",
      "          Custo Treino: 0.693\n",
      "Época 20,\n",
      "          Custo Treino: 0.693\n",
      "Época 21,\n",
      "          Custo Treino: 0.693\n",
      "Época 22,\n",
      "          Custo Treino: 0.693\n",
      "Época 23,\n",
      "          Custo Treino: 0.693\n",
      "Época 24,\n",
      "          Custo Treino: 0.693\n",
      "Época 25,\n",
      "          Custo Treino: 0.693\n",
      "Época 26,\n",
      "          Custo Treino: 0.693\n",
      "Época 27,\n",
      "          Custo Treino: 0.693\n",
      "Época 28,\n",
      "          Custo Treino: 0.693\n",
      "Época 29,\n",
      "          Custo Treino: 0.693\n",
      "Época 30,\n",
      "          Custo Treino: 0.693\n",
      "Época 31,\n",
      "          Custo Treino: 0.693\n",
      "Época 32,\n",
      "          Custo Treino: 0.693\n",
      "Época 33,\n",
      "          Custo Treino: 0.693\n",
      "Época 34,\n",
      "          Custo Treino: 0.693\n",
      "Época 35,\n",
      "          Custo Treino: 0.693\n",
      "Época 36,\n",
      "          Custo Treino: 0.693\n",
      "Época 37,\n",
      "          Custo Treino: 0.693\n",
      "Época 38,\n",
      "          Custo Treino: 0.693\n",
      "Época 39,\n",
      "          Custo Treino: 0.693\n",
      "Época 40,\n",
      "          Custo Treino: 0.693\n",
      "Época 41,\n",
      "          Custo Treino: 0.693\n",
      "Época 42,\n",
      "          Custo Treino: 0.693\n",
      "Época 43,\n",
      "          Custo Treino: 0.693\n",
      "Época 44,\n",
      "          Custo Treino: 0.693\n",
      "Época 45,\n",
      "          Custo Treino: 0.693\n",
      "Época 46,\n",
      "          Custo Treino: 0.693\n",
      "Época 47,\n",
      "          Custo Treino: 0.693\n",
      "Época 48,\n",
      "          Custo Treino: 0.693\n",
      "Época 49,\n",
      "          Custo Treino: 0.693\n",
      "Época 50,\n",
      "          Custo Treino: 0.693\n",
      "Época 51,\n",
      "          Custo Treino: 0.693\n",
      "Época 52,\n",
      "          Custo Treino: 0.693\n",
      "Época 53,\n",
      "          Custo Treino: 0.693\n",
      "Época 54,\n",
      "          Custo Treino: 0.693\n",
      "Época 55,\n",
      "          Custo Treino: 0.693\n",
      "Época 56,\n",
      "          Custo Treino: 0.693\n",
      "Época 57,\n",
      "          Custo Treino: 0.693\n",
      "Época 58,\n",
      "          Custo Treino: 0.693\n",
      "Época 59,\n",
      "          Custo Treino: 0.693\n",
      "Época 60,\n",
      "          Custo Treino: 0.693\n",
      "Época 61,\n",
      "          Custo Treino: 0.693\n",
      "Época 62,\n",
      "          Custo Treino: 0.693\n",
      "Época 63,\n",
      "          Custo Treino: 0.693\n",
      "Época 64,\n",
      "          Custo Treino: 0.693\n",
      "Época 65,\n",
      "          Custo Treino: 0.693\n",
      "Época 66,\n",
      "          Custo Treino: 0.693\n",
      "Época 67,\n",
      "          Custo Treino: 0.693\n",
      "Época 68,\n",
      "          Custo Treino: 0.693\n",
      "Época 69,\n",
      "          Custo Treino: 0.693\n",
      "Época 70,\n",
      "          Custo Treino: 0.693\n",
      "Época 71,\n",
      "          Custo Treino: 0.693\n",
      "Época 72,\n",
      "          Custo Treino: 0.693\n",
      "Época 73,\n",
      "          Custo Treino: 0.693\n",
      "Época 74,\n",
      "          Custo Treino: 0.693\n",
      "Época 75,\n",
      "          Custo Treino: 0.693\n",
      "Época 76,\n",
      "          Custo Treino: 0.693\n",
      "Época 77,\n",
      "          Custo Treino: 0.693\n",
      "Época 78,\n",
      "          Custo Treino: 0.693\n",
      "Época 79,\n",
      "          Custo Treino: 0.693\n",
      "Época 80,\n",
      "          Custo Treino: 0.693\n",
      "Época 81,\n",
      "          Custo Treino: 0.693\n",
      "Época 82,\n",
      "          Custo Treino: 0.693\n",
      "Época 83,\n",
      "          Custo Treino: 0.693\n",
      "Época 84,\n",
      "          Custo Treino: 0.693\n",
      "Época 85,\n",
      "          Custo Treino: 0.693\n",
      "Época 86,\n",
      "          Custo Treino: 0.693\n",
      "Época 87,\n",
      "          Custo Treino: 0.693\n",
      "Época 88,\n",
      "          Custo Treino: 0.693\n",
      "Época 89,\n",
      "          Custo Treino: 0.693\n",
      "Época 90,\n",
      "          Custo Treino: 0.693\n",
      "Época 91,\n",
      "          Custo Treino: 0.693\n",
      "Época 92,\n",
      "          Custo Treino: 0.693\n",
      "Época 93,\n",
      "          Custo Treino: 0.693\n",
      "Época 94,\n",
      "          Custo Treino: 0.693\n",
      "Época 95,\n",
      "          Custo Treino: 0.693\n",
      "Época 96,\n",
      "          Custo Treino: 0.693\n",
      "Época 97,\n",
      "          Custo Treino: 0.693\n",
      "Época 98,\n",
      "          Custo Treino: 0.693\n",
      "Época 99,\n",
      "          Custo Treino: 0.693\n",
      "Época 100,\n",
      "          Custo Treino: 0.693\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    model.train() # Colocar o modelo em modo de treinamento (calcula os gradientes)\n",
    "    \n",
    "    # Batch Size\n",
    "    for data in train_loader:\n",
    "        # dar nome aos bois\n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "        \n",
    "        # Propagação (Feed Forward)\n",
    "        y_pred = model(X)\n",
    "    \n",
    "        # Calcular erro usando a função-custo\n",
    "        # y precisa virar um Tensor com tamanho (batch_size, 1)\n",
    "        loss = loss_fn(y_pred, y.unsqueeze_(1))\n",
    "        \n",
    "        # Zera os gradientes antes da Retro-propagação (Backpropagation)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Retro-propagação (Backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualização dos parâmetros\n",
    "        optimizer.step()\n",
    "\n",
    "    # Fim da Época\n",
    "    print(f\"\"\"Época {t + 1},\n",
    "          Custo Treino: {round(loss.item(), 3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0abb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Treino: 0.593695\n",
      "Acurácia de Teste: 0.594406\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "    \n",
    "with torch.no_grad():  # Desabilitar gradientes durante avaliação\n",
    "    train_pred = model(X_train)\n",
    "    train_pred_binary = (train_pred > 0.5).float().flatten()\n",
    "    train_acc = torch.sum(train_pred_binary == y_train) / len(y_train)\n",
    "\n",
    "    test_pred = model(X_test)\n",
    "    test_pred_binary = (test_pred > 0.5).float().flatten()\n",
    "    test_acc = torch.sum(test_pred_binary == y_test) / len(y_test)\n",
    "\n",
    "print(f\"Acurácia de Treino: {train_acc:.6f}\")\n",
    "print(f\"Acurácia de Teste: {test_acc:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
