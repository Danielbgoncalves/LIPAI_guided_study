{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AOeBPCyDyD1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb68851-5bf1-4be1-cdf6-4685b7ff3f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.78MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.23MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.99MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# MNIST dataset\n",
        "root_path = '/home/storopoli/Downloads' # mude isso no Colab se necessário\n",
        "\n",
        "# Pequena transformação para tensores e normalizando o tamanho\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # força 3 canais\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, 0.1307, 0.1307),\n",
        "                         (0.3081, 0.3081, 0.3081))])\n",
        "\n",
        "# Train/Test Datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root=root_path, train=True, transform=trans, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=root_path, train=False, transform=trans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "34_HPQdi0ru8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features,10)"
      ],
      "metadata": {
        "id": "Lq6zP3U50y4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0176e243-33b8-42fc-b555-565c7a82db27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 217MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Congela as 4 camadas\n",
        "for param in model.layer1.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.layer2.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.layer3.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.layer4.parameters(): # True para ex 3.2\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "3YjQhQyk1FRW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Hiperparâmetros\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "epochs = 1\n",
        "\n",
        "# Instânciar o Otimizador Adam\n",
        "optimizer = Adam([\n",
        "    {\"params\": model.layer4.parameters(), \"lr\": 1e-5},  # fine-tuning devagar\n",
        "    {\"params\": model.fc.parameters(), \"lr\": 1e-3},      # última camada mais rápido\n",
        "])"
      ],
      "metadata": {
        "id": "BbUFzelI19vH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Isto tem que retornar True\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "R9Dciy322xdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2c5e11-99fa-485a-c793-cc2a71782380"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o Modelo\n",
        "total_step = len(train_loader) # quantos batches eu tenho\n",
        "\n",
        "# Listas vazias\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Gera a propagação (feed forward)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calcula a função-custo\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Retro-propagação (Backprop) e a otimização com Adam\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Acurácia\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Época [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], Custo: {round(loss.item(), 3)}, Acurácia: {round((correct / total) * 100, 3)}\")"
      ],
      "metadata": {
        "id": "LWZg0CHf21-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccbd093-bdd6-4760-b21f-d3cdbffe99e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [1/1], Step [100/1875], Custo: 0.514, Acurácia: 87.5\n",
            "Época [1/1], Step [200/1875], Custo: 0.081, Acurácia: 100.0\n",
            "Época [1/1], Step [300/1875], Custo: 0.043, Acurácia: 100.0\n",
            "Época [1/1], Step [400/1875], Custo: 0.062, Acurácia: 100.0\n",
            "Época [1/1], Step [500/1875], Custo: 0.018, Acurácia: 100.0\n",
            "Época [1/1], Step [600/1875], Custo: 0.179, Acurácia: 96.875\n",
            "Época [1/1], Step [700/1875], Custo: 0.066, Acurácia: 96.875\n",
            "Época [1/1], Step [800/1875], Custo: 0.015, Acurácia: 100.0\n",
            "Época [1/1], Step [900/1875], Custo: 0.299, Acurácia: 93.75\n",
            "Época [1/1], Step [1000/1875], Custo: 0.074, Acurácia: 96.875\n",
            "Época [1/1], Step [1100/1875], Custo: 0.003, Acurácia: 100.0\n",
            "Época [1/1], Step [1200/1875], Custo: 0.242, Acurácia: 90.625\n",
            "Época [1/1], Step [1300/1875], Custo: 0.143, Acurácia: 90.625\n",
            "Época [1/1], Step [1400/1875], Custo: 0.14, Acurácia: 93.75\n",
            "Época [1/1], Step [1500/1875], Custo: 0.01, Acurácia: 100.0\n",
            "Época [1/1], Step [1600/1875], Custo: 0.059, Acurácia: 96.875\n",
            "Época [1/1], Step [1700/1875], Custo: 0.011, Acurácia: 100.0\n",
            "Época [1/1], Step [1800/1875], Custo: 0.013, Acurácia: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # coloca o modelo em modo de avaliação (sem calcular gradientes)\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        # Feed-forward com as imagens de teste\n",
        "        outputs = model(images)\n",
        "\n",
        "        # gera predições usando a função max()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Acumula total e corretas\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Acurácia do Modelo em 10k imagens de teste: {round((correct / total) * 100, 3)}\")"
      ],
      "metadata": {
        "id": "IUAL-sRO25h9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f6c258-65ff-4fea-d6fb-e3e6c7512be9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Modelo em 10k imagens de teste: 98.91\n"
          ]
        }
      ]
    }
  ]
}